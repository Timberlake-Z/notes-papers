# Tue May 23 2025

#### 流形

##### 欧氏空间 (Euclidean Space)

<img src="/Users/timberlakezhang/Library/Application Support/typora-user-images/Screenshot 2025-05-13 at 16.24.50.png" alt="Screenshot 2025-05-13 at 16.24.50" style="zoom:50%;" />

##### 拓扑空间 (Topological Space)

<img src="/Users/timberlakezhang/Library/Application Support/typora-user-images/Screenshot 2025-05-13 at 16.25.32.png" alt="Screenshot 2025-05-13 at 16.25.32" style="zoom:50%;" />

#### **流形假设 (Manifold Hypothesis)**

- **假设：** 高维数据（如图像和文本）实际上位于**低维流形**上。（也就是分布没那么散）
- **意义：**
  - 即使数据维度很高，**有用特征往往集中在低维流形上**。
  - **降维方法：** 利用流形假设进行特征提取和降维，如**PCA**、**t-SNE**、**Isomap**。
  - **神经网络：** 学习特征表示时，假设隐藏层的表示位于低维流形上。

# Wed

主要看了SSL相关的一个论文，讨论SSL中OOD的影响，**How Out-of-Distribution Data Hurts Semi-Supervised Learning**

## 1️⃣ pseudo-label 

这个方法比较直观，就是直接给unlabeled data 用model 做一个prediction，再assign回来训练

## 2️⃣ Consistency Regularization

### 1. VAT

SSL方法，但没有assign label给unlabeled data，而是计算**无标签数据在扰动下的预测变化**，最小化这种变化，提升模型对扰动的鲁棒性

1. 对抗扰动基于平滑假设，一个点的局部不应该扰动太大，扰动太大说明决策边界很陡峭，容易过拟合。
2. 即便在真实决策边界很陡峭，也应该让他更鲁棒。（不改变决策边界，而是让他平滑）

### 2. Pi-mdoel

1. 不找最强扰动，而是随机增强和扰动，计算复杂度低一点
   1. <img src="/Users/timberlakezhang/Library/Application Support/typora-user-images/Screenshot 2025-05-14 at 18.01.25.png" alt="Screenshot 2025-05-14 at 18.01.25" style="zoom:50%;" />

### 3. Mean-teacher

1. 有两个model，teacher model 和 student model。其中teacher model是strudent model 的moving average。（滑动窗口）
2. 训练的结果是student model，teacher model起到一个辅助作用。学生Loss中的一致性损失是对unlabeled data 在 stu 和 teacher两个model 输出的一致性损失，但是其实赋的augmentation不一样。（两个层面考虑robustness呗）
3. 只管来看就是加了个model辅助，让他变化不那么快，但是不太能get

## 3️⃣ Pseudo + consistency regularization 

### 1. FixMatch

1. 只assign 高置信度的标签，设一个threshold
2. 一致性损失对unlabeled data assigned的label做
3. <img src="/Users/timberlakezhang/Desktop/Screenshot 2025-05-14 at 18.53.43.png" alt="Screenshot 2025-05-14 at 18.53.43" style="zoom:50%;" />